apiVersion: v1
kind: ConfigMap
metadata:
  name: vector-config
data:
  vector.yaml: |
    # Vector configuration for multi-tenant logging
    data_dir: "/vector-data-dir"
    
    api:
      enabled: true
      address: "0.0.0.0:8686"
      playground: false
    
    # Sources
    sources:
      kubernetes_logs:
        type: "kubernetes_logs"
        # Only collect logs from specific namespace
        extra_field_selector: "metadata.namespace=clusters-jhjaggars-test"
        glob_minimum_cooldown_ms: 1000
        auto_partial_merge: true
    
    # Transforms
    transforms:
      enrich_metadata:
        type: "remap"
        inputs: ["kubernetes_logs"]
        source: |
          # Extract tenant information from pod annotations
          .customer_id = .kubernetes.pod_annotations."customer-id" || "test-customer"
          .cluster_id = get_env_var!("CLUSTER_ID") || "scuppett-oepz"
          .environment = .kubernetes.pod_annotations."environment" || "development"
          .application = .kubernetes.pod_annotations."application" || .kubernetes.pod_labels."app" || "unknown"
          .pod_name = .kubernetes.pod_name || "unknown"
          
          # Extract log level if present
          log_level_match = parse_regex(.message, r'(?P<level>TRACE|DEBUG|INFO|WARN|ERROR|FATAL)') ?? {}
          .log_level = log_level_match.level || "INFO"
          
          # Add timestamp if not present
          if !exists(.timestamp) {
            .timestamp = now()
          }
          
          # Clean up kubernetes metadata to reduce payload size
          del(.kubernetes.pod_labels)
          del(.kubernetes.pod_annotations)
          .kubernetes = object({
            "namespace": .kubernetes.pod_namespace,
            "pod_name": .kubernetes.pod_name,
            "container_name": .kubernetes.container_name,
            "node_name": .kubernetes.pod_node_name
          })
          
      # Remove filter since we're targeting specific namespace
    
    # Sinks
    sinks:
      s3_logs:
        type: "aws_s3"
        inputs: ["enrich_metadata"]
        
        # S3 bucket configuration
        bucket: "${S3_BUCKET_NAME}"
        region: "${AWS_REGION}"
        
        # Dynamic key prefix based on tenant metadata
        key_prefix: "{{ customer_id }}/{{ cluster_id }}/{{ application }}/{{ pod_name }}/"
        
        # Batch settings
        batch:
          max_bytes: 10485760  # 10MB
          timeout_secs: 300    # 5 minutes
        
        # Request settings
        request:
          retry_attempts: 3
          retry_initial_backoff_secs: 1
          retry_max_duration_secs: 30
          timeout_secs: 30
        
        # Compression
        compression: "gzip"
        
        # File format
        encoding:
          codec: "json"
          framing:
            method: "newline_delimited"
        
        # Buffer configuration
        buffer:
          type: "disk"
          max_size: 10737418240  # 10GB
          when_full: "block"
        
        # Authentication via IRSA
        auth:
          assume_role: "${S3_WRITER_ROLE_ARN}"
          
        # Add timestamp to filename
        filename_append_uuid: true
        filename_time_format: "%Y%m%d-%H%M%S"
        filename_extension: "json.gz"